{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作业：手写数字加法机\n",
    "\n",
    "本文件是与集智AI学园出品的系列课程“火炬上的深度学习”配套的作业notebook。本作业要求学员构造一个卷积神经网，输入两张手写数字图片，输出这两个数字的和。\n",
    "\n",
    "本文件提供了一个完成做的大框架，学员需要自行修改、添加代码，从而完成任务\n",
    "\n",
    "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第III课的配套源代码\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需要的包，请保证torchvision已经在你的环境中安装好\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义需要用到的超参数\n",
    "image_size = 28  #图像的总尺寸28*28\n",
    "num_classes = 10  #标签的种类数\n",
    "num_epochs = 20  #训练的总循环周期\n",
    "batch_size = 64\n",
    "\n",
    "# 加载MINIST数据，如果没有下载过，就会在当前路径下新建/data子目录，并把文件存放其中\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data',  #文件存放路径\n",
    "                            train=True,   #提取训练集\n",
    "                            transform=transforms.ToTensor(),  #将图像转化为Tensor\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "# 由于每一个样本需要输入两个图片，因此每一个loader和sampler都有两个\n",
    "\n",
    "sampler1 = torch.utils.data.sampler.SubsetRandomSampler(\n",
    "    np.random.permutation(range(len(train_dataset))))\n",
    "sampler2 = torch.utils.data.sampler.SubsetRandomSampler(\n",
    "    np.random.permutation(range(len(train_dataset))))\n",
    "\n",
    "# 训练数据的两个加载器\n",
    "train_loader1 = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = False,\n",
    "                                           sampler = sampler1\n",
    "                                           )\n",
    "train_loader2 = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = False,\n",
    "                                           sampler = sampler2\n",
    "                                           )\n",
    "\n",
    "# 校验数据和测试数据都各自有两套\n",
    "val_size = 5000\n",
    "val_indices1 = range(val_size)\n",
    "val_indices2 = np.random.permutation(range(val_size))\n",
    "test_indices1 = range(val_size, len(test_dataset))\n",
    "test_indices2 = np.random.permutation(test_indices1)\n",
    "val_sampler1 = torch.utils.data.sampler.SubsetRandomSampler(val_indices1)\n",
    "val_sampler2 = torch.utils.data.sampler.SubsetRandomSampler(val_indices2)\n",
    "\n",
    "test_sampler1 = torch.utils.data.sampler.SubsetRandomSampler(test_indices1)\n",
    "test_sampler2 = torch.utils.data.sampler.SubsetRandomSampler(test_indices2)\n",
    "\n",
    "val_loader1 = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                        batch_size = batch_size,\n",
    "                                        shuffle = False,\n",
    "                                        sampler = val_sampler1\n",
    "                                        )\n",
    "val_loader2 = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                        batch_size = batch_size,\n",
    "                                        shuffle = False,\n",
    "                                        sampler = val_sampler2\n",
    "                                        )\n",
    "test_loader1 = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle = False,\n",
    "                                         sampler = test_sampler1\n",
    "                                         )\n",
    "test_loader2 = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle = False,\n",
    "                                         sampler = test_sampler2\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINST Adder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了实现加法器，需要同时处理两个手写体数字图像，并对它进行相应的图像处理\n",
    "因此，网络的架构为两个卷积神经网络，串联上两个全链接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth = [4, 8]\n",
    "# class MINSTAdder(nn.Module):\n",
    "#    def __init__(self):\n",
    "#        super(MINSTAdder, self).__init__()\n",
    "#        #处理第一个图像处理用的卷积网络部件\n",
    "#        self.net1_conv1 = nn.Conv2d(1, 4, 5, padding = 2)\n",
    "#        self.net_pool = nn.MaxPool2d(2, 2)\n",
    "#        self.net1_conv2 = nn.Conv2d(depth[0], depth[1], 5, padding = 2)\n",
    "        \n",
    "#        #处理第二个图像处理用的卷积网络部件\n",
    "#        self.net2_conv1 = nn.Conv2d(1, 4, 5, padding = 2)\n",
    "#        self.net2_conv2 = nn.Conv2d(depth[0], depth[1], 5, padding = 2)\n",
    "        \n",
    "#        #后面的全连阶层\n",
    "#        self.fc1 = nn.Linear(2 * image_size // 4 * image_size // 4 * depth[1] , 1024)\n",
    "#        self.fc2 = nn.Linear(1024, 1)\n",
    "\n",
    "#    def forward(self, x, y, training = True):\n",
    "#        #第一张图像的处理流程\n",
    "#        x = F.relu(self.net1_conv1(x))\n",
    "#        x = self.net_pool(x)\n",
    "#        x = F.relu(self.net1_conv2(x))\n",
    "#        x = self.net_pool(x)\n",
    "#        x = x.view(-1, image_size // 4 * image_size // 4 * depth[1])\n",
    "        \n",
    "#        #第二张图像的处理流程\n",
    "#        y = F.relu(self.net2_conv1(y))\n",
    "#        y = self.net_pool(y)\n",
    "#        y = F.relu(self.net2_conv2(y))\n",
    "#        y = self.net_pool(y)\n",
    "#        y = y.view(-1, image_size // 4 * image_size // 4 * depth[1])\n",
    "        \n",
    "#        #将前两部处理得到的张量并列到一起，喂给两层全链接前馈网络，最后输出预测数值\n",
    "#        z = torch.cat((x, y), 1)\n",
    "#        z = self.fc1(z)\n",
    "#        z = F.relu(z)\n",
    "#        z = F.dropout(z, training=self.training) #以默认为0.5的概率对这一层进行dropout操作\n",
    "#        z = self.fc2(z)\n",
    "#        return z\n",
    "\n",
    "# # 计算准确度的函数（有多少数字给出了严格的正确输出结果）\n",
    "# def rightness(y, target):\n",
    "#    out = torch.round(y).type(torch.LongTensor)\n",
    "#    out = out.eq(target).sum()\n",
    "#    out1 = y.size()[0]\n",
    "#    return(out, out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #将网络定义为一个预测器，来对加法的结果进行预测，因此用MSE平均平房误差作为我们的损失函数\n",
    "# net = MINSTAdder()\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr = 0.0001, momentum = 0.9)\n",
    "# results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #开始训练循环，本部分代码需要补齐\n",
    "# num_epochs = 20\n",
    "# records = []\n",
    "# for epoch in range(num_epochs):\n",
    "#    losses = []\n",
    "#    # 一个关键技术难点是对两个数据加载器进行读取成对儿的数据。我们的办法是通过zip命令，将loader1和2并列在一起，一对一对的读取数据\n",
    "#    for idx, data in enumerate(zip(train_loader1, train_loader2)):\n",
    "#        ((x1, y1), (x2, y2)) = data\n",
    "#        optimizer.zero_grad()\n",
    "#        net.train()\n",
    "#        outputs = net(x1, x2)\n",
    "#        labels = y1 + y2\n",
    "#        loss = criterion(outputs, labels.type(torch.float))\n",
    "#        if idx % 100 == 0:\n",
    "#            #每间隔一定周期就打印一下训练集、校验集的准确率结果\n",
    "#            print('第{}周期，第({}/{})个撮，训练误差：{:.2f}, 校验误差：{:.2f}, 准确率：{:.2f}'.format(\n",
    "#                epoch, idx, len(train_loader1),\n",
    "#                np.mean(losses), np.mean(val_losses), right_ratio))\n",
    "#            records.append([np.mean(losses), np.mean(val_losses), right_ratio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 在测试集上运行我们的加法机网络，并测试预测准确度\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
